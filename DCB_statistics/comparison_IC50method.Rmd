---
title: "comparison_IC50method"
author: "yomiyama"
date: "2021/11/30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(drc)
```

## required packages

```{r eval=FALSE}
library(tidyverse)
library(drc)
```


```{r}
conc1=c(0.3, 0.3, 0.3, 1, 1, 1, 3, 3, 3, 10, 10, 10, 30, 30, 30, 100, 100, 100, 300, 300, 300, 1000, 1000, 1000, 3000, 3000, 3000);
RLU1=c(243, 284, 330, 338, 425, 365, 1667, 1578, 1674, 5552, 5415, 5121, 8177, 8926, 7485, 10442, 10865, 9343, 11547, 11709, 11654, 12252, 10118, 12380, 11946, 12135, 10272)

nls1<-function(x,y,z){
  1/27*sum(
    (y-(z[1]+(z[2]-z[1])/(1+10^(z[3]*(z[4]-log10(x))))))^2 
    )
}

res5<-optim(c(200,8000,1,1.2),nls1,x=conc1,y=RLU1,
            method = "BFGS",hessian = TRUE)
SE<-sqrt(diag(solve(res5$hessian*
                      (length(conc1))/(2*res5$value)
                    )))

B<-diag(solve(res5$hessian*(length(conc1))/(2*res5$value)))
B<-sqrt(B)

t1<-res5$par/SE

tp<-2*(1-pt(abs(t1),(length(conc1)-4)))
tp
res=nls(RLU1~base+(max-base)/(1+10^(n*(logEC50-log10(conc1)))), start=c(base=200, max=12000, logEC50=1.2, n=1))

summary(res)
```



```{R}

dat<-read.csv("D:/Other_program/VBA/Nov_25th_EC50_training.csv",header=TRUE)
dat<-dat[,-1]
dat


conc<-as.vector(dat[,1])

resp<-as.matrix(dat[,2:ncol(dat)])


resp_a <- c(resp[,1:3]) #阻害剤が入っていない実験
resp_b <- c(resp[,4:6]) #阻害剤が入っている実験

conc<-rep(conc, 3)

dat_a<-data.frame(conc,resp_a)

dat_a<-na.omit(dat_a)

dat_b<-data.frame(conc,resp_b)

dat_b<-na.omit(dat_b)
###################

llf2<-function(x,y,z){
  
  sum((y-100/(1+10^(z[1]*(z[2]-x))))^2)
}


res_nl<-nlm(f = llf2,c(-1,-5),x=dat_a$conc,y=dat_a$resp_a,hessian=TRUE)

```


```{r}


llf2_2<-function(x,z){
  100/(1+10^(z[1]*(z[2]-x)))
}

res_nl_a<-optim(c(1,-5),llf2,x=dat_a$conc,y=dat_a$resp_a,hessian=TRUE)

res_nl_b<-optim(c(1,-5),llf2,x=dat_b$conc,y=dat_b$resp_b,hessian=TRUE)

hx<-deriv(y~100/(1+10^(hill*(EC-x))),c("hill","EC"),function(x,y,hill,EC){}
      )

fr_a<-hx(dat_a$conc,dat_a$resp_a,res_nl_a$par[1],res_nl_a$par[2])
fr_a
fr_b<-hx(dat_b$conc,dat_b$resp_b,res_nl_b$par[1],res_nl_b$par[2])
fr_b
G_a<-attr(fr_a,"gradient")
z_a<-dat_a$resp_a-llf2_2(dat_a$conc,res_nl_a$par)+
  G_a%*%res_nl_a$par

G_b<-attr(fr_b,"gradient")
z_b<-dat_b$resp_b-llf2_2(dat_b$conc,res_nl_b$par)+
  G_b%*%res_nl_b$par

solve(t(G_a)%*%G_a)%*%t(G_a)%*%z_a
solve(t(G_b)%*%G_b)%*%t(G_b)%*%z_b

V.lin_a<-res_nl_a$value/(nrow(dat_a)-length(res_nl_a$par))*solve(t(G_a)%*%G_a)
V.lin_b<-res_nl_b$value/(nrow(dat_b)-length(res_nl_b$par))*solve(t(G_b)%*%G_b)


se.lin_a<-sqrt(diag(V.lin_a))
se.lin_a

se.lin_b<-sqrt(diag(V.lin_b))
se.lin_b


```



```{R}
#####maximum likelyhood1

llf2<-function(x,y,z){
  
  sum((y-100/(1+10^(z[1]*(z[2]-x))))^2)
}
res_a<-optim(c(1,-5),llf2,x=dat_a$conc,y=dat_a$resp_a,method = "L-BFGS-B",hessian = TRUE)

res_b<-optim(c(1,-5),llf2,x=dat_b$conc,y=dat_b$resp_b,method = "L-BFGS-B",hessian = TRUE)

reso_a<-matrix(0,2,2)
colnames(reso_a)<-c("hill","EC50")

  
for(i in 1:2){
  reso_a[1,i]<-res_a$par[i]
  reso_a[2,i]<-sqrt(2*res_a$value/(nrow(dat_a))*
                      solve(res_a$hessian[i,i]))
}

reso_b<-matrix(0,2,2)
colnames(reso_b)<-c("hill","EC50")

  
for(i in 1:2){
  reso_b[1,i]<-res_b$par[i]
  reso_b[2,i]<-sqrt(2*res_b$value/(nrow(dat_b))*solve(res_b$hessian[i,i])*2)
}

reso_a

reso_b

  
  
#####maximum likelyhood2

llf3<-function(x,y,n,z){
 1/n*sum(y*log(100/(1+10^(z[1]*(z[2]-x))))+
        (100-y)*(log(100-(100)/(1+10^(z[1]*(z[2]-x))))))
  
}

res_o<-optim(c(1,-5),llf3,x=dat_a$conc,y=dat_a$resp_a,
            n=nrow(dat_a), control = list(fnscale=-1),method = "L-BFGS-B",hessian = TRUE)

res_o

res_o2<-optim(c(1,-5),llf3,x=dat_b$conc,y=dat_b$resp_b,
             n=nrow(dat_b),control = list(fnscale=-1),method = "L-BFGS-B",hessian = TRUE)

sqrt(abs(diag(solve(res_o$hessian))))

res_o2

sqrt(abs(diag(solve(res_o2$hessian))))
```


### 重み付け

####絶対的重み付け(Absolute)

$$

\Sigma(Y_{data}-Y_{curve})^2= \Sigma (Y_{data}-Y_{pred})^2
$$


#### 相対的重み付け(Relative)

$$

\Sigma(\frac{Y_{data}-Y_{curve}}{Y_{pred}})^2= \Sigma \frac{(Y_{data}-Y_{pred})^2}{Y^2_{pred}}

$$

#### Poisson重み付け


実距離の二乗和を最小化するやり方と相対距離の二乗和を最小化する方式を折衷したもの。
Y値がPoisson分布に従う場合に適している。
Poisson分布では標準誤差がその値の平方根

$$

\Sigma(\frac{Y_{data}-Y_{curve}}{\sqrt{Y_{pred}}})^2= \Sigma \frac{(Y_{data}-Y_{pred})^2}{|Y_{pred}|}

$$


#### 一般化した重み付け

$$

\Sigma(\frac{Y_{data}-Y_{curve}}{Y_{pred}^{\frac{K}{2}}})^2= \Sigma \frac{(Y_{data}-Y_{pred})^2}{Y_{pred}^K}

$$



#### 限られた場合に用いられる重み付け方式

$\frac{1}{X}$や$\frac{1}{X^2}$による重み付けを選択した場合、グラフの左側の点ほど大きく重みがかかる。
生物学的検定データに直線をフィッティングさせるなどの分野でよく使われる。
またいかのような標準偏差の二乗の逆数による重み付けも可能。
$$
\Sigma(\frac{Y_{data}-Y_{curve}}{SD})^2= \Sigma \frac{(Y_{data}-Y_{pred})^2}{SD^2}

$$



なおこの場合のSD自体は実データから計算した標準偏差でなく理論値に基づいて計算される。




